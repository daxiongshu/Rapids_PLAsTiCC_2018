{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf as gd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import xgboost as xgb\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_MEMORY = 32 # GB. please change it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ROWS = 453653104 # number of rows in test data\n",
    "# no skip if your gpu has 32 GB memory\n",
    "# otherwise, skip rows porportionally\n",
    "SKIP_ROWS = int((1 - GPU_MEMORY/32.0)*TEST_ROWS) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "\n",
    "class Timer(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._timer = default_timer\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.start = self._timer()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
    "        self.end = self._timer()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_weighted_logloss(y_true, y_preds, classes, class_weights):\n",
    "    \"\"\"\n",
    "    refactor from\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order='F')\n",
    "    # Trasform y_true in dummies\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    # Normalize rows and limit y_preds to 1e-15, 1-1e-15\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    # Transform to log\n",
    "    y_p_log = np.log(y_p)\n",
    "    # Get the log for ones, .values is used to drop the index of DataFrames\n",
    "    # Exclude class 99 for now, since there is no class99 in the training set\n",
    "    # we gave a special process for that class\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    # Get the number of positives for each class\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    # Weight average and divide by the number of positives\n",
    "    class_arr = np.array([class_weights[k] for k in sorted(class_weights.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = - np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss\n",
    "\n",
    "def xgb_multi_weighted_logloss(y_predicted, y_true, classes, class_weights):\n",
    "    loss = multi_weighted_logloss(y_true.get_label(), y_predicted, \n",
    "                                  classes, class_weights)\n",
    "    return 'wloss', loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ravel_column_names(cols):\n",
    "    d0 = cols.get_level_values(0)\n",
    "    d1 = cols.get_level_values(1)\n",
    "    return [\"%s_%s\"%(i,j) for i,j in zip(d0,d1)]\n",
    "    \n",
    "def etl_cpu(df,df_meta):\n",
    "    df['flux_ratio_sq'] = np.power(df['flux'] / df['flux_err'], 2.0)\n",
    "    df['flux_by_flux_ratio_sq'] = df['flux'] * df['flux_ratio_sq']\n",
    "    aggs = {\n",
    "        'passband': ['mean'], \n",
    "        'flux': ['min', 'max', 'mean'],\n",
    "        'flux_err': ['min', 'max', 'mean'],\n",
    "        'detected': ['mean'],\n",
    "        'mjd':['max','min'],\n",
    "        'flux_ratio_sq':['sum'],\n",
    "        'flux_by_flux_ratio_sq':['sum'],\n",
    "    }\n",
    "    agg_df = df.groupby('object_id').agg(aggs)\n",
    "    agg_df.columns = ravel_column_names(agg_df.columns)\n",
    "    \n",
    "    agg_df['flux_diff'] = agg_df['flux_max'] - agg_df['flux_min']\n",
    "    agg_df['flux_dif2'] = (agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_mean']\n",
    "    agg_df['flux_w_mean'] = agg_df['flux_by_flux_ratio_sq_sum'] / agg_df['flux_ratio_sq_sum']\n",
    "    agg_df['flux_dif3'] = (agg_df['flux_max'] - agg_df['flux_min']) / agg_df['flux_w_mean']\n",
    "    \n",
    "    agg_df['mjd_diff'] = agg_df['mjd_max'] - agg_df['mjd_min']\n",
    "    agg_df = agg_df.drop(['mjd_max','mjd_min'],axis=1)\n",
    "    \n",
    "    agg_df = agg_df.reset_index()\n",
    "    df_meta = df_meta.drop(['ra','decl','gal_l','gal_b'],axis=1)\n",
    "    df_meta = df_meta.merge(agg_df,on='object_id',how='left')\n",
    "    return df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save GPU memory, we drop the column as soon as it is done with groupby\n",
    "# \n",
    "# this hits performance a little but avoids GPU OOM.\n",
    "def groupby_aggs(df,aggs,col):\n",
    "    res = None\n",
    "    for i,j in aggs.items():\n",
    "        for k in j:\n",
    "            #print(i,k)\n",
    "            tmp = df.groupby(col).agg({i:[k]})\n",
    "            if res is None:\n",
    "                res = tmp\n",
    "            else:\n",
    "                res = res.merge(tmp,on=[col],how='left')\n",
    "        df.drop_column(i)\n",
    "    return res\n",
    "\n",
    "def etl_gpu(df,df_meta):\n",
    "    aggs = {\n",
    "        'passband': ['mean'], \n",
    "        'detected': ['mean'],\n",
    "        'mjd':['max','min'],\n",
    "    }\n",
    "    agg_df = groupby_aggs(df,aggs,'object_id')\n",
    "    # at this step, columns ['passband','detected','mjd'] are deleted \n",
    "    \n",
    "    df['flux_ratio_sq'] = df['flux'] / df['flux_err']\n",
    "    df['flux_ratio_sq'] = df['flux_ratio_sq'].applymap(lambda x: math.pow(x,2))\n",
    "    df['flux_by_flux_ratio_sq'] = df['flux'] * df['flux_ratio_sq']\n",
    "    \n",
    "    aggs2 = {\n",
    "        'flux_ratio_sq':['sum'],\n",
    "        'flux_by_flux_ratio_sq':['sum'],\n",
    "        'flux': ['min', 'max', 'mean'],\n",
    "        'flux_err': ['min', 'max', 'mean'],\n",
    "    }\n",
    "    agg_df2 = groupby_aggs(df,aggs2,'object_id')\n",
    "    agg_df = agg_df.merge(agg_df2,on=['object_id'],how='left')\n",
    "    del agg_df2\n",
    "\n",
    "    agg_df['flux_diff'] = agg_df['max_flux'] - agg_df['min_flux']\n",
    "    agg_df['flux_dif2'] = (agg_df['max_flux'] - agg_df['min_flux']) / agg_df['mean_flux']\n",
    "    agg_df['flux_w_mean'] = agg_df['sum_flux_by_flux_ratio_sq'] / agg_df['sum_flux_ratio_sq']\n",
    "    agg_df['flux_dif3'] = (agg_df['max_flux'] - agg_df['min_flux']) / agg_df['flux_w_mean']\n",
    "    \n",
    "    agg_df['mjd_diff'] = agg_df['max_mjd'] - agg_df['min_mjd']\n",
    "    agg_df.drop_column('max_mjd')\n",
    "    agg_df.drop_column('min_mjd')\n",
    "    \n",
    "    for col in ['ra','decl','gal_l','gal_b']:\n",
    "        df_meta.drop_column(col)\n",
    "    \n",
    "    df_meta = df_meta.merge(agg_df,on=['object_id'],how='left')\n",
    "    return df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 40s, sys: 47.5 s, total: 5min 27s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read data on cpu\n",
    "test = pd.read_csv('../input/test_set.csv')\n",
    "test_meta = pd.read_csv('../input/test_set_metadata.csv')\n",
    "\n",
    "train = pd.read_csv('../input/training_set.csv')\n",
    "train_meta = pd.read_csv('../input/training_set_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 7.06 s, total: 27.2 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read data on gpu\n",
    "ts_cols = ['object_id', 'mjd', 'passband', 'flux', 'flux_err', 'detected']\n",
    "ts_dtypes = ['int32', 'float32', 'int32', 'float32','float32','int32']\n",
    "\n",
    "test_gd = gd.read_csv('../input/test_set.csv',\n",
    "            names=ts_cols,dtype=ts_dtypes,skiprows=1+SKIP_ROWS) # skip the header\n",
    "train_gd = gd.read_csv('../input/training_set.csv',\n",
    "            names=ts_cols,dtype=ts_dtypes,skiprows=1)\n",
    "\n",
    "cols = ['object_id', 'ra', 'decl', 'gal_l', 'gal_b', 'ddf',\n",
    "       'hostgal_specz', 'hostgal_photoz', 'hostgal_photoz_err', \n",
    "       'distmod','mwebv', 'target']\n",
    "dtypes = ['int32']+['float32']*4+['int32']+['float32']*5+['int32']\n",
    "\n",
    "train_meta_gd = gd.read_csv('../input/training_set_metadata.csv',\n",
    "            names=cols,dtype=dtypes,skiprows=1)\n",
    "del cols[-1],dtypes[-1]\n",
    "test_meta_gd = gd.read_csv('../input/test_set_metadata.csv',\n",
    "            names=cols,dtype=dtypes,skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.09 s, sys: 148 ms, total: 9.24 s\n",
      "Wall time: 233 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CPU\n",
    "train_final = etl_cpu(train,train_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:int32\n",
      "2:int32\n",
      "3:int32\n",
      "1:int32\n",
      "1:int32\n",
      "2:int32\n",
      "3:float32\n",
      "1:int32\n",
      "1:int32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:int32\n",
      "1:int32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "1:int32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:int32\n",
      "2:int32\n",
      "3:int32\n",
      "3:int32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "CPU times: user 1.2 s, sys: 224 ms, total: 1.42 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GPU\n",
    "train_final_gd = etl_gpu(train_gd,train_meta_gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 1s, sys: 2min 24s, total: 6min 26s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CPU\n",
    "test_final = etl_cpu(test,test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:int32\n",
      "2:int32\n",
      "3:int32\n",
      "1:int32\n",
      "1:int32\n",
      "2:int32\n",
      "3:float32\n",
      "1:int32\n",
      "1:int32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "1:int32\n",
      "1:int32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "1:int32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "1:float32\n",
      "2:int32\n",
      "3:int32\n",
      "3:int32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "3:float32\n",
      "CPU times: user 3.84 s, sys: 3.11 s, total: 6.96 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GPU\n",
    "test_final_gd = etl_gpu(test_gd,test_meta_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 15 16 42 52 53 62 64 65 67 88 90 92 95]\n"
     ]
    }
   ],
   "source": [
    "# CPU\n",
    "X = train_final.drop(['object_id','target'],axis=1).values\n",
    "y = train_final['target']\n",
    "Xt = test_final.drop(['object_id'],axis=1).values\n",
    "assert X.shape[1] == Xt.shape[1]\n",
    "classes = sorted(y.unique())    \n",
    "# Taken from Giba's topic : https://www.kaggle.com/titericz\n",
    "# https://www.kaggle.com/c/PLAsTiCC-2018/discussion/67194\n",
    "# with Kyle Boone's post https://www.kaggle.com/kyleboone\n",
    "class_weights = {c: 1 for c in classes}\n",
    "class_weights.update({c:2 for c in [64, 15]})\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "y = lbl.fit_transform(y)\n",
    "print(lbl.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_params = {\n",
    "            'objective': 'multi:softprob', \n",
    "            'tree_method': 'hist', \n",
    "            'nthread': 16, \n",
    "            'num_class':14,\n",
    "            'max_depth': 7, \n",
    "            'silent':1,\n",
    "            'subsample':0.7,\n",
    "            'colsample_bytree': 0.7,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_loss = partial(xgb_multi_weighted_logloss, \n",
    "                        classes=classes, \n",
    "                        class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:18:10] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "[0]\teval-merror:0.332484\ttrain-merror:0.27637\teval-wloss:1.98637\ttrain-wloss:1.85982\n",
      "Multiple eval metrics have been passed: 'train-wloss' will be used for early stopping.\n",
      "\n",
      "Will train until train-wloss hasn't improved in 10 rounds.\n",
      "[49]\teval-merror:0.273885\ttrain-merror:0.00538\teval-wloss:1.26831\ttrain-wloss:0.131698\n",
      "validation loss 1.2683\n",
      "CPU times: user 5min 31s, sys: 1.98 s, total: 5min 33s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
    "dtest = xgb.DMatrix(data=Xt)\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "clf = xgb.train(cpu_params, dtrain=dtrain,\n",
    "                num_boost_round=50,evals=watchlist,\n",
    "                feval=func_loss,early_stopping_rounds=10,\n",
    "                verbose_eval=1000)\n",
    "yp = clf.predict(dvalid)\n",
    "loss = multi_weighted_logloss(y_test, yp, classes, class_weights)\n",
    "ysub = clf.predict(dtest)\n",
    "print('validation loss %.4f'%loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "y = train_final_gd['target'].to_array()\n",
    "y = lbl.fit_transform(y)\n",
    "for col in ['object_id','target']:\n",
    "    train_final_gd.drop_column(col)\n",
    "for col in train_final_gd.columns:\n",
    "    train_final_gd[col] = train_final_gd[col].fillna(0).astype('float32')\n",
    "X = train_final_gd.as_matrix()\n",
    "\n",
    "for col in ['object_id']:\n",
    "    test_final_gd.drop_column(col)\n",
    "for col in test_final_gd.columns:\n",
    "    test_final_gd[col] = test_final_gd[col].fillna(0).astype('float32')\n",
    "Xt = test_final_gd.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "gpu_params = cpu_params.copy()\n",
    "gpu_params.update({'objective': 'multi:softprob',\n",
    "                   'tree_method': 'gpu_hist', \n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.323567\ttrain-merror:0.276795\teval-wloss:2.00989\ttrain-wloss:1.94981\n",
      "Multiple eval metrics have been passed: 'train-wloss' will be used for early stopping.\n",
      "\n",
      "Will train until train-wloss hasn't improved in 10 rounds.\n",
      "[49]\teval-merror:0.26879\ttrain-merror:0.008637\teval-wloss:1.12085\ttrain-wloss:0.150667\n",
      "validation loss 1.1208\n",
      "CPU times: user 1min 12s, sys: 1.44 s, total: 1min 13s\n",
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
    "dtest = xgb.DMatrix(data=Xt)\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "clf = xgb.train(gpu_params, dtrain=dtrain,\n",
    "                num_boost_round=50,evals=watchlist,\n",
    "                feval=func_loss,early_stopping_rounds=10,\n",
    "                verbose_eval=1000)\n",
    "yp = clf.predict(dvalid)\n",
    "loss = multi_weighted_logloss(y_test, yp, classes, class_weights)\n",
    "ysub = clf.predict(dtest)\n",
    "print('validation loss %.4f'%loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
